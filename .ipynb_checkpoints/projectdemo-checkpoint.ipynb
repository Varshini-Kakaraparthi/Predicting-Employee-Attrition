{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpLp9EAkAcOw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, InputLayer\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('HR_Analytics.csv')\n",
        "\n",
        "# Drop irrelevant or constant columns\n",
        "columns_to_drop = ['EmployeeCount', 'Over18', 'StandardHours', 'EmployeeNumber']\n",
        "df.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
        "\n",
        "# Encode target variable\n",
        "target_column = 'Attrition'\n",
        "label_encoder = LabelEncoder()\n",
        "df[target_column] = label_encoder.fit_transform(df[target_column])\n",
        "\n",
        "# Handle missing values appropriately\n",
        "numeric_cols = df.select_dtypes(include='number').columns\n",
        "categorical_cols = df.select_dtypes(exclude='number').columns\n",
        "\n",
        "# Fill missing values\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "df[categorical_cols] = df[categorical_cols].fillna(df[categorical_cols].mode().iloc[0])\n",
        "\n",
        "# Identify categorical and numerical columns\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.drop(target_column)\n",
        "\n",
        "# Encode categorical columns using OneHotEncoder\n",
        "for col in categorical_cols:\n",
        "    if df[col].dtype in [np.int64, np.float64]:\n",
        "        continue  # Skip if already numeric\n",
        "    if df[col].nunique() == 2:\n",
        "        df[col] = LabelEncoder().fit_transform(df[col])\n",
        "    else:\n",
        "        onehot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "        encoded_data = onehot_encoder.fit_transform(df[[col]])\n",
        "        encoded_df = pd.DataFrame(encoded_data, columns=[f\"{col}_{cat}\" for cat in onehot_encoder.categories_[0]])\n",
        "        df = df.drop(col, axis=1).join(encoded_df)\n",
        "\n",
        "# Split features and target\n",
        "X = df.drop(target_column, axis=1)\n",
        "y = df[target_column]\n",
        "\n",
        "# Standardize numerical features\n",
        "scaler = StandardScaler()\n",
        "X[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n",
        "\n",
        "# Ensure all columns in X are numeric\n",
        "X = X.select_dtypes(include=['number'])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Prepare LSTM input (reshape for sequential model)\n",
        "X_train_lstm = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test_lstm = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "# LSTM Model (using InputLayer)\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(InputLayer(shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
        "lstm_model.add(LSTM(50, activation='relu'))\n",
        "lstm_model.add(Dropout(0.3))\n",
        "lstm_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train LSTM\n",
        "lstm_model.fit(X_train_lstm, y_train, epochs=30, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# XGBoost Model with Hyperparameter Tuning using GridSearchCV\n",
        "xgb_model = xgb.XGBClassifier(eval_metric='logloss')\n",
        "\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "best_xgb_model = grid_search.best_estimator_  # Get the best XGBoost model\n",
        "\n",
        "# Evaluate Models\n",
        "def evaluate_model(model, X_test, y_test, model_type=\"LSTM\"):\n",
        "    if model_type == \"LSTM\":\n",
        "        X_test_reshaped = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "        y_pred = model.predict(X_test_reshaped)\n",
        "        y_pred = (y_pred > 0.5).astype(int)\n",
        "    elif model_type == \"Hybrid\":\n",
        "        y_pred = model(X_test)  # Call lambda function for Hybrid\n",
        "    else:\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "    print(f\"{model_type} - Accuracy: {accuracy * 100:.2f}%\")\n",
        "    print(f\"{model_type} - Precision: {precision * 100:.2f}%\")\n",
        "    print(f\"{model_type} - Recall: {recall * 100:.2f}%\")\n",
        "    print(f\"{model_type} - F1-score: {f1 * 100:.2f}%\")\n",
        "\n",
        "# Evaluate both models\n",
        "evaluate_model(lstm_model, X_test, y_test, \"LSTM\")\n",
        "evaluate_model(best_xgb_model, X_test, y_test, \"XGBoost\")  # Use the best XGBoost model\n",
        "\n",
        "# Hybrid Prediction (Averaging probabilities)\n",
        "lstm_prob = lstm_model.predict(X_test_lstm).flatten()\n",
        "xgb_prob = best_xgb_model.predict_proba(X_test)[:, 1]  # Use best_xgb_model\n",
        "\n",
        "hybrid_prob = (lstm_prob + xgb_prob) / 2\n",
        "hybrid_pred = (hybrid_prob > 0.5).astype(int)\n",
        "\n",
        "# Evaluate Hybrid Model (using lambda function)\n",
        "print(\"\\nHybrid Model Performance:\")\n",
        "evaluate_model(lambda x: hybrid_pred, X_test, y_test, \"Hybrid\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict attrition for new data\n",
        "def predict_attrition(new_employee_data):\n",
        "    new_employee_df = pd.DataFrame([new_employee_data])\n",
        "\n",
        "    # One-hot encode categorical features in new data\n",
        "    for col in categorical_cols:\n",
        "        if col in new_employee_df.columns:\n",
        "            if new_employee_df[col].nunique() == 2:\n",
        "                new_employee_df[col] = LabelEncoder().fit_transform(new_employee_df[col])\n",
        "            else:\n",
        "                # Get one-hot encoded columns from training data\n",
        "                onehot_cols = [c for c in X_train.columns if c.startswith(col + '_')]\n",
        "\n",
        "                # Create one-hot encoded columns for new data, filled with 0\n",
        "                for onehot_col in onehot_cols:\n",
        "                    new_employee_df[onehot_col] = 0\n",
        "\n",
        "                # Set the appropriate one-hot column to 1 based on the value in new data\n",
        "                value = new_employee_df[col][0]  # Get the value of the categorical feature\n",
        "\n",
        "\n",
        "                matching_col = col + '_' + str(value)\n",
        "\n",
        "                if matching_col in new_employee_df.columns:\n",
        "                    new_employee_df[matching_col] = 1\n",
        "\n",
        "    # Drop original categorical columns\n",
        "    new_employee_df = new_employee_df.drop(categorical_cols, axis=1, errors='ignore')\n",
        "    # Reindex to match the training data columns\n",
        "\n",
        "    new_employee_df = new_employee_df.reindex(columns=X_train.columns, fill_value=0)\n",
        "   # print(new_employee_df.columns)\n",
        "    # LSTM Prediction\n",
        "    lstm_input = new_employee_df.values.reshape((1, 1, X_train.shape[1]))\n",
        "    lstm_prediction = lstm_model.predict(lstm_input).flatten()[0]\n",
        "\n",
        "    # XGBoost Prediction (using best model)\n",
        "    xgb_prediction = best_xgb_model.predict_proba(new_employee_df)[:, 1][0]  # Use best_xgb_model\n",
        "\n",
        "    # Hybrid Prediction\n",
        "    hybrid_prediction = (lstm_prediction + xgb_prediction) / 2\n",
        "\n",
        "    if hybrid_prediction < 0.06:\n",
        "        print(\"Prediction: Employee is likely to leave.\")\n",
        "    else:\n",
        "        print(\"Prediction: Employee is likely to stay.\")\n"
      ],
      "metadata": {
        "id": "RBxBbYLAAzWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained LSTM model\n",
        "lstm_model.save('lstm_model.h5')\n",
        "\n",
        "# Save the best XGBoost model\n",
        "joblib.dump(best_xgb_model, 'best_xgb_model.pkl')\n",
        "\n",
        "# Save the label encoder\n",
        "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
        "\n",
        "# Save the standard scaler\n",
        "joblib.dump(scaler, 'scaler.pkl')\n"
      ],
      "metadata": {
        "id": "Muy4U2lZAeEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#No\n",
        "# Example usage with new_employee_data:\n",
        "new_employee_data = {\n",
        "    'Age': 49,\n",
        "    'Department': 'Research & Development',\n",
        "    'JobRole': 'Research Scientist',\n",
        "    'JobSatisfaction': 2,\n",
        "    'MaritalStatus': 'Married',\n",
        "    'MonthlyIncome': 5130,\n",
        "    'OverTime': 'NO',\n",
        "    'PercentSalaryHike': 23,\n",
        "    'PerformanceRating': 4,\n",
        "    'StockOptionLevel': 1,\n",
        "    'TotalWorkingYears': 10,\n",
        "    'WorkLifeBalance': 3,\n",
        "    'YearsAtCompany': 10,\n",
        "    'YearsInCurrentRole': 7,\n",
        "    'YearsSinceLastPromotion': 1,\n",
        "}\n",
        "\n",
        "predict_attrition(new_employee_data)"
      ],
      "metadata": {
        "id": "oM8kVfnuAf7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Yes\n",
        "# Example usage with new_employee_data:\n",
        "new_employee_data = {\n",
        "    'Age': 41,\n",
        "    'Department': 'Sales',\n",
        "    'JobRole': 'Sales Executive',\n",
        "    'JobSatisfaction': 4,\n",
        "    'MaritalStatus': 'Single',\n",
        "    'MonthlyIncome': 5993,\n",
        "    'OverTime': 'YES',\n",
        "    'PercentSalaryHike': 11,\n",
        "    'PerformanceRating': 3,\n",
        "    'StockOptionLevel': 0,\n",
        "    'TotalWorkingYears': 8,\n",
        "    'WorkLifeBalance': 1,\n",
        "    'YearsAtCompany': 6,\n",
        "    'YearsInCurrentRole': 4,\n",
        "    'YearsSinceLastPromotion': 0,\n",
        "}\n",
        "\n",
        "predict_attrition(new_employee_data)"
      ],
      "metadata": {
        "id": "0NKRHh6iAmAV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}